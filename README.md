# LDA_Model_TopicModeling
Example of a study of a LDA (Latent Dirichlet Allocation) model trained on Wikipedia person data. We need an initial preprocessing of text to then categorise into 20 groups and then perform an exploration of what is contained in each group created. So in this example we have text cleaning, lemmatisation, tokenisation and tokenisation. 
